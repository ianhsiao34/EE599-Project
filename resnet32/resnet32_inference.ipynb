{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fb18d4-66d7-421d-bf00-63460b5c60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128 CUDA: True\n",
      "TensorRT: 10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"TensorRT:\", trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20c95b9-71ae-476f-9fe5-3997105ecf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "from models.cifar_resnet32 import ResNet32\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd93386-e7a2-4028-8377-27899c33347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet32(num_classes=10)\n",
    "model.load_state_dict(\n",
    "    torch.load(\"checkpoints/resnet32_fp32_best.pt\", map_location=\"cpu\")\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ea8db1-83f3-4806-8401-14ac8fcedd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5267562/ipykernel_66159/1035872847.py:12: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported resnet32_fp32_b1_op13.onnx\n",
      "Exported resnet32_fp32_b64_op13.onnx\n",
      "Exported resnet32_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "dummy_map = {\n",
    "    1:   torch.randn(1,   3, 32, 32),\n",
    "    64:  torch.randn(64,  3, 32, 32),\n",
    "    128: torch.randn(128, 3, 32, 32),\n",
    "}\n",
    "\n",
    "for bs, dummy in dummy_map.items():\n",
    "    out_path = f\"resnet32_fp32_b{bs}_op13.onnx\"\n",
    "    torch.onnx.export(\n",
    "        model, dummy, out_path,\n",
    "        opset_version=13,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes=None,   # <-- IMPORTANT: static\n",
    "        dynamo=False\n",
    "    )\n",
    "    print(\"Exported\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17143253-186e-4c27-ad4a-c67f1e4d6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 1.8M Dec 13 08:21 resnet32_fp32_b1_op13.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.8M Dec 13 08:21 resnet32_fp32_b64_op13.onnx\n",
      "-rw-r--r-- 1 ihsiao ihsiao 1.8M Dec 13 08:21 resnet32_fp32_b128_op13.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh resnet32_fp32_b1_op13.onnx\n",
    "!ls -lh resnet32_fp32_b64_op13.onnx\n",
    "!ls -lh resnet32_fp32_b128_op13.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85a783e-e0c7-4e28-ae74-93c7507e8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 13)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet32_fp32_b1_op13.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "print([(op.domain, op.version) for op in m.opset_import])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ac89d5-edbc-4178-b9e1-8f408f840f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "print(trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0c6a83-4e52-4242-aea3-229a1256bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/13/2025-08:23:25] [TRT] [W] WARNING The logger passed into createInferBuilder differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
      "[12/13/2025-08:23:25] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:25] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/13/2025-08:23:25] [TRT] [I] Opset version:    13\n",
      "[12/13/2025-08:23:25] [TRT] [I] Producer name:    pytorch\n",
      "[12/13/2025-08:23:25] [TRT] [I] Producer version: 2.9.1\n",
      "[12/13/2025-08:23:25] [TRT] [I] Domain:           \n",
      "[12/13/2025-08:23:25] [TRT] [I] Model version:    0\n",
      "[12/13/2025-08:23:25] [TRT] [I] Doc string:       \n",
      "[12/13/2025-08:23:25] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:25] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/13/2025-08:23:32] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/13/2025-08:23:33] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/13/2025-08:23:33] [TRT] [I] Total Host Persistent Memory: 188784 bytes\n",
      "[12/13/2025-08:23:33] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/13/2025-08:23:33] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/13/2025-08:23:33] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 36 steps to complete.\n",
      "[12/13/2025-08:23:33] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.206257ms to assign 3 blocks to 36 nodes requiring 196608 bytes.\n",
      "[12/13/2025-08:23:33] [TRT] [I] Total Activation Memory: 196608 bytes\n",
      "[12/13/2025-08:23:33] [TRT] [I] Total Weights Memory: 1877032 bytes\n",
      "[12/13/2025-08:23:33] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/13/2025-08:23:33] [TRT] [I] Engine generation completed in 7.61011 seconds.\n",
      "[12/13/2025-08:23:33] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 6 MiB\n",
      "Saved: resnet32_fp32_b1.engine\n",
      "[12/13/2025-08:23:33] [TRT] [W] WARNING The logger passed into createInferBuilder differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
      "[12/13/2025-08:23:33] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:33] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/13/2025-08:23:33] [TRT] [I] Opset version:    13\n",
      "[12/13/2025-08:23:33] [TRT] [I] Producer name:    pytorch\n",
      "[12/13/2025-08:23:33] [TRT] [I] Producer version: 2.9.1\n",
      "[12/13/2025-08:23:33] [TRT] [I] Domain:           \n",
      "[12/13/2025-08:23:33] [TRT] [I] Model version:    0\n",
      "[12/13/2025-08:23:33] [TRT] [I] Doc string:       \n",
      "[12/13/2025-08:23:33] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:33] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/13/2025-08:23:40] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/13/2025-08:23:40] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/13/2025-08:23:40] [TRT] [I] Total Host Persistent Memory: 187120 bytes\n",
      "[12/13/2025-08:23:40] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/13/2025-08:23:40] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/13/2025-08:23:40] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 36 steps to complete.\n",
      "[12/13/2025-08:23:40] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.20267ms to assign 3 blocks to 36 nodes requiring 12582912 bytes.\n",
      "[12/13/2025-08:23:40] [TRT] [I] Total Activation Memory: 12582912 bytes\n",
      "[12/13/2025-08:23:40] [TRT] [I] Total Weights Memory: 1877376 bytes\n",
      "[12/13/2025-08:23:40] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/13/2025-08:23:40] [TRT] [I] Engine generation completed in 7.42501 seconds.\n",
      "[12/13/2025-08:23:40] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 13 MiB\n",
      "Saved: resnet32_fp32_b64.engine\n",
      "[12/13/2025-08:23:41] [TRT] [W] WARNING The logger passed into createInferBuilder differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
      "[12/13/2025-08:23:41] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:41] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/13/2025-08:23:41] [TRT] [I] Opset version:    13\n",
      "[12/13/2025-08:23:41] [TRT] [I] Producer name:    pytorch\n",
      "[12/13/2025-08:23:41] [TRT] [I] Producer version: 2.9.1\n",
      "[12/13/2025-08:23:41] [TRT] [I] Domain:           \n",
      "[12/13/2025-08:23:41] [TRT] [I] Model version:    0\n",
      "[12/13/2025-08:23:41] [TRT] [I] Doc string:       \n",
      "[12/13/2025-08:23:41] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/13/2025-08:23:41] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/13/2025-08:23:47] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/13/2025-08:23:48] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/13/2025-08:23:48] [TRT] [I] Total Host Persistent Memory: 188976 bytes\n",
      "[12/13/2025-08:23:48] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/13/2025-08:23:48] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/13/2025-08:23:48] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 37 steps to complete.\n",
      "[12/13/2025-08:23:48] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.231374ms to assign 4 blocks to 37 nodes requiring 25166336 bytes.\n",
      "[12/13/2025-08:23:48] [TRT] [I] Total Activation Memory: 25165824 bytes\n",
      "[12/13/2025-08:23:48] [TRT] [I] Total Weights Memory: 1876864 bytes\n",
      "[12/13/2025-08:23:48] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/13/2025-08:23:48] [TRT] [I] Engine generation completed in 7.36673 seconds.\n",
      "[12/13/2025-08:23:48] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 25 MiB\n",
      "Saved: resnet32_fp32_b128.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# IMPORTANT: these ONNX files must be exported with FIXED batch sizes (static)\n",
    "onnx_map = {\n",
    "    1:   \"resnet32_fp32_b1_op13.onnx\",\n",
    "    64:  \"resnet32_fp32_b64_op13.onnx\",\n",
    "    128: \"resnet32_fp32_b128_op13.onnx\",\n",
    "}\n",
    "\n",
    "def build_static_engine(onnx_path, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(f\"ONNX parse failed for {onnx_path}\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # NO optimization profile => static engine (uses whatever fixed shape is in ONNX)\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(f\"Engine build failed for {onnx_path}\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "for bs, onnx_path in onnx_map.items():\n",
    "    engine_path = f\"resnet32_fp32_b{bs}.engine\"\n",
    "    build_static_engine(onnx_path, engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37bac398-e290-467b-bf6c-a49cc60b1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 2.0M Dec 13 08:23 resnet32_fp32_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 13 08:23 resnet32_fp32_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 13 08:23 resnet32_fp32_b128.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 12 23:49 resnet32_fp32_b1to128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh resnet32_fp32_b1.engine\n",
    "!ls -lh resnet32_fp32_b64.engine\n",
    "!ls -lh resnet32_fp32_b128.engine\n",
    "!ls -lh resnet32_fp32_b1to128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa592380-cf3a-43a7-bfdf-19ee4c109118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e3c7a-9050-46fe-afba-923879d3509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "def benchmark_engine(engine_path, batch_size, iters=1000):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    context.set_input_shape(inp, (batch_size, 3, 32, 32))\n",
    "    x = torch.randn(batch_size, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out, int(y.data_ptr()))\n",
    "\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    end.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = start.elapsed_time(end)\n",
    "\n",
    "    batch_latency = elapsed_ms / iters\n",
    "    batch_latency_ms = elapsed_ms / iters\n",
    "    throughput = (iters * batch_size) / (elapsed_ms / 1000.0)\n",
    "    ms_per_img = batch_latency_ms / batch_size\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch_size}\")\n",
    "    print(f\"  latency:    {batch_latency:.3f} ms/batch\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput: {throughput:.1f} images/sec\")\n",
    "\n",
    "# âœ… CALL IT (this is the part people miss)\n",
    "print(\"Starting benchmark...\")\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=1, iters=1000)\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=64, iters=1000)\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=128, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fef28b-35fb-4387-97d2-5195cae56b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def run_engine(engine_path, batch):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    # load engine\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # names\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # shape + buffers\n",
    "    context.set_input_shape(inp_name, (batch, 3, 32, 32))\n",
    "    x = torch.randn(batch, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out_name)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out_name, int(y.data_ptr()))\n",
    "\n",
    "    # use a non-default CUDA stream (avoids TRT warning)\n",
    "    stream = torch.cuda.Stream()\n",
    "    torch.cuda.set_stream(stream)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed (CUDA events = accurate GPU timing)\n",
    "    iters = 1000\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    starter.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    ender.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = starter.elapsed_time(ender)  # total ms over iters\n",
    "    batch_latency_ms = elapsed_ms / iters\n",
    "    img_per_sec = (iters * batch) / (elapsed_ms / 1000.0)\n",
    "    ms_per_img = batch_latency_ms / batch\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch}\")\n",
    "    print(f\"  batch latency: {batch_latency_ms:.3f} ms\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:    {img_per_sec:.1f} images/sec\")\n",
    "\n",
    "# ONE dynamic engine that supports 1..128\n",
    "engine = \"resnet32_fp32_b1to128.engine\"\n",
    "for bs in [1, 64, 128]:\n",
    "    run_engine(engine, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98a1ad-c6f5-4040-acf5-c85243cc2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(50):\n",
    "    context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "stream.synchronize()\n",
    "\n",
    "iters = 1000\n",
    "\n",
    "starter = torch.cuda.Event(enable_timing=True)\n",
    "ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "starter.record(stream)\n",
    "for _ in range(iters):\n",
    "    context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "ender.record(stream)\n",
    "\n",
    "stream.synchronize()\n",
    "\n",
    "elapsed_ms = starter.elapsed_time(ender)  # total GPU time\n",
    "\n",
    "latency_ms = elapsed_ms / iters                  # ms per batch\n",
    "throughput = (iters * batch_size) / (elapsed_ms / 1000.0)\n",
    "\n",
    "print(f\"Latency:    {latency_ms:.3f} ms / batch\")\n",
    "print(f\"Throughput:{throughput:.1f} images/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfa043-1872-4920-873f-04560db1663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "onnx_path = \"resnet32_fp32_dyn.onnx\"   # must be exported with dynamic batch\n",
    "\n",
    "def build_fp16_engine_dynamic(engine_path, max_bs=128):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(\"ONNX parse failed\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # enable FP16\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "        # one profile supports batch 1..max_bs\n",
    "        profile = builder.create_optimization_profile()\n",
    "        inp_name = network.get_input(0).name\n",
    "        profile.set_shape(\n",
    "            inp_name,\n",
    "            min=(1, 3, 32, 32),\n",
    "            opt=(min(64, max_bs), 3, 32, 32),\n",
    "            max=(max_bs, 3, 32, 32),\n",
    "        )\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(\"Engine build failed\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "build_fp16_engine_dynamic(\"resnet32_fp16_b1to128.engine\", max_bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff36bb1-0473-480e-96e4-239d24e4e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh resnet32_fp16_b1.engine\n",
    "!ls -lh resnet32_fp16_b64.engine\n",
    "!ls -lh resnet32_fp16_b128.engine\n",
    "!ls -lh resnet32_fp16_b1to128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb914e1-f19a-42c2-b8e4-04ae245d5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "def run_engine(engine_path, batch, iters=1000, warmup=50):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    context.set_input_shape(inp_name, (batch, 3, 32, 32))\n",
    "\n",
    "    x = torch.randn(batch, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out_name)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out_name, int(y.data_ptr()))\n",
    "\n",
    "    # non-default stream + GPU-accurate timing\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    end.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = start.elapsed_time(end)          # total ms for iters\n",
    "    batch_latency_ms = elapsed_ms / iters         # ms per batch\n",
    "    ms_per_img = batch_latency_ms / batch\n",
    "    img_per_sec = (iters * batch) / (elapsed_ms / 1000.0)\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch}\")\n",
    "    print(f\"  batch latency: {batch_latency_ms:.3f} ms/batch\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:    {img_per_sec:.1f} images/sec\")\n",
    "\n",
    "# latency case\n",
    "run_engine(\"resnet32_fp16_b1.engine\", 1)\n",
    "\n",
    "# throughput cases\n",
    "run_engine(\"resnet32_fp16_b64.engine\", 64)\n",
    "run_engine(\"resnet32_fp16_b128.engine\", 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f0dd1-9496-4b88-add3-6ab7503cd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0ea02-1c28-416f-917b-48b6789cd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_accuracy(engine_path, test_loader, num_batches=None):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # map TRT dtype -> torch dtype for output buffer\n",
    "    trt_dtype = engine.get_tensor_dtype(out)\n",
    "    torch_dtype = {\n",
    "        trt.DataType.FLOAT: torch.float32,\n",
    "        trt.DataType.HALF:  torch.float16,\n",
    "        trt.DataType.INT8:  torch.int8,\n",
    "        trt.DataType.INT32: torch.int32,\n",
    "    }[trt_dtype]\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    stream = torch.cuda.current_stream()\n",
    "\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(test_loader):\n",
    "        if num_batches is not None and bi >= num_batches:\n",
    "            break\n",
    "\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "        bsz = x.shape[0]\n",
    "\n",
    "        # dynamic engines: set shape each batch (ok)\n",
    "        context.set_input_shape(inp, (bsz, 3, 32, 32))\n",
    "        out_shape = tuple(context.get_tensor_shape(out))\n",
    "\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=torch_dtype)\n",
    "\n",
    "        context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "        context.set_tensor_address(out, int(yhat.data_ptr()))\n",
    "\n",
    "        ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"TRT execute failed\")\n",
    "\n",
    "        pred = yhat.float().argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += bsz\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e04cc8-22e8-41d7-9345-d5bd98464ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fp32 = trt_accuracy(\"resnet32_fp32_b1to128.engine\", test_loader)\n",
    "print(f\"TRT FP32 Test Acc: {acc_fp32:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffe9cf-4ea9-4d56-9285-6c1ef58cee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = ResNet32(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"checkpoints/resnet32_fp32_best.pt\", map_location=\"cpu\"))\n",
    "model.eval().cuda()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "        pred = model(x).argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(\"PyTorch FP32 Test Acc:\", 100*correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
