{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fb18d4-66d7-421d-bf00-63460b5c60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu128 CUDA: True\n",
      "TensorRT: 10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
    "print(\"TensorRT:\", trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20c95b9-71ae-476f-9fe5-3997105ecf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "from models.cifar_resnet32 import ResNet32\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd93386-e7a2-4028-8377-27899c33347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet32(num_classes=10)\n",
    "model.load_state_dict(\n",
    "    torch.load(\"checkpoints/resnet32_fp32_best.pt\", map_location=\"cpu\")\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ea8db1-83f3-4806-8401-14ac8fcedd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_5267562/ipykernel_4103091/2621133282.py:5: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported resnet32_fp32_dyn.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dummy = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model, dummy,\n",
    "    \"resnet32_fp32_dyn.onnx\",\n",
    "    opset_version=13,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
    "    dynamo=False\n",
    ")\n",
    "print(\"Exported resnet32_fp32_dyn.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85a783e-e0c7-4e28-ae74-93c7507e8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 13)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "m = onnx.load(\"resnet32_fp32_op13.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "print([(op.domain, op.version) for op in m.opset_import])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ac89d5-edbc-4178-b9e1-8f408f840f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.14.1.48.post1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "print(trt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0c6a83-4e52-4242-aea3-229a1256bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/12/2025-23:49:47] [TRT] [I] [MemUsageChange] Init CUDA: CPU +16, GPU +0, now: CPU 173, GPU 422 (MiB)\n",
      "[12/12/2025-23:49:48] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/12/2025-23:49:48] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/12/2025-23:49:48] [TRT] [I] Opset version:    13\n",
      "[12/12/2025-23:49:48] [TRT] [I] Producer name:    pytorch\n",
      "[12/12/2025-23:49:48] [TRT] [I] Producer version: 2.9.1\n",
      "[12/12/2025-23:49:48] [TRT] [I] Domain:           \n",
      "[12/12/2025-23:49:48] [TRT] [I] Model version:    0\n",
      "[12/12/2025-23:49:48] [TRT] [I] Doc string:       \n",
      "[12/12/2025-23:49:48] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/12/2025-23:49:48] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +281, GPU +8, now: CPU 663, GPU 430 (MiB)\n",
      "[12/12/2025-23:49:48] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/12/2025-23:49:55] [TRT] [I] Compiler backend is used during engine build.\n",
      "[12/12/2025-23:49:56] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/12/2025-23:49:56] [TRT] [I] Total Host Persistent Memory: 187120 bytes\n",
      "[12/12/2025-23:49:56] [TRT] [I] Total Device Persistent Memory: 0 bytes\n",
      "[12/12/2025-23:49:56] [TRT] [I] Max Scratch Memory: 0 bytes\n",
      "[12/12/2025-23:49:56] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 36 steps to complete.\n",
      "[12/12/2025-23:49:56] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.222467ms to assign 3 blocks to 36 nodes requiring 25165824 bytes.\n",
      "[12/12/2025-23:49:56] [TRT] [I] Total Activation Memory: 25165824 bytes\n",
      "[12/12/2025-23:49:56] [TRT] [I] Total Weights Memory: 1877376 bytes\n",
      "[12/12/2025-23:49:56] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[12/12/2025-23:49:56] [TRT] [I] Engine generation completed in 8.49119 seconds.\n",
      "[12/12/2025-23:49:56] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 25 MiB\n",
      "Saved: resnet32_fp32_b1to128.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "onnx_path   = \"resnet32_fp32_dyn.onnx\"\n",
    "engine_path = \"resnet32_fp32_b1to128.engine\"\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "     builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "     trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "    with open(onnx_path, \"rb\") as f:\n",
    "        if not parser.parse(f.read()):\n",
    "            for i in range(parser.num_errors):\n",
    "                print(parser.get_error(i))\n",
    "            raise RuntimeError(\"ONNX parse failed\")\n",
    "\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "    # ---- ONE dynamic-batch profile (1..128) ----\n",
    "    inp_name = network.get_input(0).name\n",
    "    profile = builder.create_optimization_profile()\n",
    "    profile.set_shape(inp_name,\n",
    "                      (1,   3, 32, 32),   # min\n",
    "                      (64,  3, 32, 32),   # opt (typical)\n",
    "                      (128, 3, 32, 32))   # max\n",
    "    config.add_optimization_profile(profile)\n",
    "    # -------------------------------------------\n",
    "\n",
    "    serialized = builder.build_serialized_network(network, config)\n",
    "    if serialized is None:\n",
    "        raise RuntimeError(\"Engine build failed\")\n",
    "\n",
    "    with open(engine_path, \"wb\") as f:\n",
    "        f.write(serialized)\n",
    "\n",
    "print(\"Saved:\", engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bac398-e290-467b-bf6c-a49cc60b1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ihsiao ihsiao 2.0M Dec 12 18:26 resnet32_fp32_b1.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 12 18:26 resnet32_fp32_b64.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 12 18:26 resnet32_fp32_b128.engine\n",
      "-rw-r--r-- 1 ihsiao ihsiao 2.1M Dec 12 23:49 resnet32_fp32_b1to128.engine\n"
     ]
    }
   ],
   "source": [
    "!ls -lh resnet32_fp32_b1.engine\n",
    "!ls -lh resnet32_fp32_b64.engine\n",
    "!ls -lh resnet32_fp32_b128.engine\n",
    "!ls -lh resnet32_fp32_b1to128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e4cef-8b7e-4ea2-b7b4-e5bcd3310026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6e3c7a-9050-46fe-afba-923879d3509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting benchmark...\n",
      "[12/12/2025-23:52:04] [TRT] [W] WARNING The logger passed into createInferRuntime differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
      "resnet32_fp32_b1to128.engine | batch=1\n",
      "  latency:    0.394 ms/batch\n",
      "  throughput: 2538.0 images/sec\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "\n",
    "def benchmark_engine(engine_path, batch_size, iters=1000):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    context.set_input_shape(inp, (batch_size, 3, 32, 32))\n",
    "    x = torch.randn(batch_size, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out, int(y.data_ptr()))\n",
    "\n",
    "    stream = torch.cuda.Stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    end.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = start.elapsed_time(end)\n",
    "\n",
    "    batch_latency = elapsed_ms / iters\n",
    "    throughput = (iters * batch_size) / (elapsed_ms / 1000.0)\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch_size}\")\n",
    "    print(f\"  latency:    {batch_latency:.3f} ms/batch\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput: {throughput:.1f} images/sec\")\n",
    "\n",
    "# âœ… CALL IT (this is the part people miss)\n",
    "print(\"Starting benchmark...\")\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=1, iters=1000)\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=64, iters=1000)\n",
    "benchmark_engine(\"resnet32_fp32_b1to128.engine\", batch_size=128, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fef28b-35fb-4387-97d2-5195cae56b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def run_engine(engine_path, batch):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    # load engine\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # names\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # shape + buffers\n",
    "    context.set_input_shape(inp_name, (batch, 3, 32, 32))\n",
    "    x = torch.randn(batch, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out_name)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out_name, int(y.data_ptr()))\n",
    "\n",
    "    # use a non-default CUDA stream (avoids TRT warning)\n",
    "    stream = torch.cuda.Stream()\n",
    "    torch.cuda.set_stream(stream)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed (CUDA events = accurate GPU timing)\n",
    "    iters = 1000\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    starter.record(stream)\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    ender.record(stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    elapsed_ms = starter.elapsed_time(ender)  # total ms over iters\n",
    "    batch_latency_ms = elapsed_ms / iters\n",
    "    img_per_sec = (iters * batch) / (elapsed_ms / 1000.0)\n",
    "    ms_per_img = batch_latency_ms / batch\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch}\")\n",
    "    print(f\"  batch latency: {batch_latency_ms:.3f} ms\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:    {img_per_sec:.1f} images/sec\")\n",
    "\n",
    "# ONE dynamic engine that supports 1..128\n",
    "engine = \"resnet32_fp32_b1to128.engine\"\n",
    "for bs in [1, 64, 128]:\n",
    "    run_engine(engine, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98a1ad-c6f5-4040-acf5-c85243cc2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(50):\n",
    "    context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "stream.synchronize()\n",
    "\n",
    "iters = 1000\n",
    "\n",
    "starter = torch.cuda.Event(enable_timing=True)\n",
    "ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "starter.record(stream)\n",
    "for _ in range(iters):\n",
    "    context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "ender.record(stream)\n",
    "\n",
    "stream.synchronize()\n",
    "\n",
    "elapsed_ms = starter.elapsed_time(ender)  # total GPU time\n",
    "\n",
    "latency_ms = elapsed_ms / iters                  # ms per batch\n",
    "throughput = (iters * batch_size) / (elapsed_ms / 1000.0)\n",
    "\n",
    "print(f\"Latency:    {latency_ms:.3f} ms / batch\")\n",
    "print(f\"Throughput:{throughput:.1f} images/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfa043-1872-4920-873f-04560db1663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "onnx_path = \"resnet32_fp32_dyn.onnx\"\n",
    "\n",
    "def build_fp16_engine(bs, engine_path):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "        with open(onnx_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for i in range(parser.num_errors):\n",
    "                    print(parser.get_error(i))\n",
    "                raise RuntimeError(\"ONNX parse failed\")\n",
    "\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "        # enable FP16\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "        # optimization profile for this batch size\n",
    "        profile = builder.create_optimization_profile()\n",
    "        inp_name = network.get_input(0).name\n",
    "        profile.set_shape(inp_name,\n",
    "                          min=(1, 3, 32, 32),\n",
    "                          opt=(bs, 3, 32, 32),\n",
    "                          max=(bs, 3, 32, 32))\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "        serialized = builder.build_serialized_network(network, config)\n",
    "        if serialized is None:\n",
    "            raise RuntimeError(\"Engine build failed\")\n",
    "\n",
    "        with open(engine_path, \"wb\") as f:\n",
    "            f.write(serialized)\n",
    "\n",
    "    print(\"Saved:\", engine_path)\n",
    "\n",
    "for bs in [1, 64, 128]:\n",
    "    build_fp16_engine(bs, f\"resnet32_fp16_b{bs}.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff36bb1-0473-480e-96e4-239d24e4e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh resnet32_fp16_b1.engine\n",
    "!ls -lh resnet32_fp16_b64.engine\n",
    "!ls -lh resnet32_fp16_b128.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb914e1-f19a-42c2-b8e4-04ae245d5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def run_engine(engine_path, batch):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    # load engine\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # names\n",
    "    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out_name  = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    # shape + buffers\n",
    "    context.set_input_shape(inp_name, (batch, 3, 32, 32))\n",
    "    x = torch.randn(batch, 3, 32, 32, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty(tuple(context.get_tensor_shape(out_name)), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    context.set_tensor_address(inp_name, int(x.data_ptr()))\n",
    "    context.set_tensor_address(out_name, int(y.data_ptr()))\n",
    "\n",
    "    stream = torch.cuda.current_stream()\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(50):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    # timed\n",
    "    iters = 10\n",
    "    t0 = time.time()\n",
    "    for _ in range(iters):\n",
    "        context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "    stream.synchronize()\n",
    "    t1 = time.time()\n",
    "\n",
    "    batch_latency_ms = (t1 - t0) * 1000 / iters\n",
    "    img_per_sec = (iters * batch) / (t1 - t0)\n",
    "    ms_per_img = batch_latency_ms / batch\n",
    "\n",
    "    print(f\"{engine_path} | batch={batch}\")\n",
    "    print(f\"  batch latency: {batch_latency_ms:.3f} ms\")\n",
    "    print(f\"  per-image:     {ms_per_img:.6f} ms/image\")\n",
    "    print(f\"  throughput:    {img_per_sec:.1f} images/sec\")\n",
    "\n",
    "# latency case\n",
    "run_engine(\"resnet32_fp16_b1.engine\", 1)\n",
    "\n",
    "# throughput cases\n",
    "run_engine(\"resnet32_fp16_b64.engine\", 64)\n",
    "run_engine(\"resnet32_fp16_b128.engine\", 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f0dd1-9496-4b88-add3-6ab7503cd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0ea02-1c28-416f-917b-48b6789cd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "@torch.no_grad()\n",
    "def trt_accuracy(engine_path, test_loader, num_batches=None):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "    # load engine\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # tensor names\n",
    "    names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
    "    inp = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
    "    out = [n for n in names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    stream = torch.cuda.current_stream()\n",
    "\n",
    "    for bi, (x_cpu, y_cpu) in enumerate(test_loader):\n",
    "        if num_batches is not None and bi >= num_batches:\n",
    "            break\n",
    "\n",
    "        # move batch to GPU\n",
    "        x = x_cpu.to(\"cuda\", non_blocking=True)\n",
    "        y = y_cpu.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "        bsz = x.shape[0]\n",
    "\n",
    "        # set shape + allocate output\n",
    "        context.set_input_shape(inp, tuple(x.shape))  # (B,3,32,32)\n",
    "        out_shape = tuple(context.get_tensor_shape(out))  # (B,10)\n",
    "        yhat = torch.empty(out_shape, device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "        # bind pointers\n",
    "        context.set_tensor_address(inp, int(x.data_ptr()))\n",
    "        context.set_tensor_address(out, int(yhat.data_ptr()))\n",
    "\n",
    "        ok = context.execute_async_v3(stream_handle=stream.cuda_stream)\n",
    "        if not ok:\n",
    "            raise RuntimeError(\"TRT execute failed\")\n",
    "        stream.synchronize()\n",
    "\n",
    "        pred = yhat.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += bsz\n",
    "\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e04cc8-22e8-41d7-9345-d5bd98464ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fp32 = trt_accuracy(\"resnet32_fp32.engine\", test_loader)\n",
    "print(f\"TRT FP32 Test Acc: {acc_fp32:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee599 (PyTorch)",
   "language": "python",
   "name": "ee599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
